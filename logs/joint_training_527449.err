/home/sentanoe/miniconda3/envs/env_graph2route/lib/python3.6/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
  0%|          | 0/40 [00:00<?, ?it/s, current_loss=0, epoch=0, loss=0]/home/sentanoe/joint_training/algorithm/graph2route_pd/tft.py:180: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  sparse_weights = self.softmax(sparse_weights).unsqueeze(2)
  0%|          | 0/40 [00:00<?, ?it/s, current_loss=2.85, epoch=0, loss=2.85]  2%|▎         | 1/40 [00:01<01:03,  1.64s/it, current_loss=2.85, epoch=0, loss=2.85]  2%|▎         | 1/40 [00:03<01:03,  1.64s/it, current_loss=2.79, epoch=0, loss=2.82]  5%|▌         | 2/40 [00:04<01:13,  1.94s/it, current_loss=2.79, epoch=0, loss=2.82]  5%|▌         | 2/40 [00:05<01:13,  1.94s/it, current_loss=2.87, epoch=0, loss=2.84]  8%|▊         | 3/40 [00:06<01:20,  2.17s/it, current_loss=2.87, epoch=0, loss=2.84]  8%|▊         | 3/40 [00:08<01:20,  2.17s/it, current_loss=2.8, epoch=0, loss=2.83]  10%|█         | 4/40 [00:09<01:26,  2.41s/it, current_loss=2.8, epoch=0, loss=2.83] 10%|█         | 4/40 [00:11<01:26,  2.41s/it, current_loss=2.84, epoch=0, loss=2.83] 12%|█▎        | 5/40 [00:12<01:29,  2.54s/it, current_loss=2.84, epoch=0, loss=2.83] 12%|█▎        | 5/40 [00:14<01:29,  2.54s/it, current_loss=2.83, epoch=0, loss=2.83] 15%|█▌        | 6/40 [00:15<01:29,  2.64s/it, current_loss=2.83, epoch=0, loss=2.83] 15%|█▌        | 6/40 [00:17<01:29,  2.64s/it, current_loss=2.79, epoch=0, loss=2.83] 18%|█▊        | 7/40 [00:18<01:29,  2.71s/it, current_loss=2.79, epoch=0, loss=2.83] 18%|█▊        | 7/40 [00:20<01:29,  2.71s/it, current_loss=2.79, epoch=0, loss=2.82] 20%|██        | 8/40 [00:21<01:27,  2.74s/it, current_loss=2.79, epoch=0, loss=2.82] 20%|██        | 8/40 [00:22<01:27,  2.74s/it, current_loss=2.81, epoch=0, loss=2.82] 22%|██▎       | 9/40 [00:24<01:25,  2.75s/it, current_loss=2.81, epoch=0, loss=2.82] 22%|██▎       | 9/40 [00:25<01:25,  2.75s/it, current_loss=2.85, epoch=0, loss=2.82] 25%|██▌       | 10/40 [00:26<01:21,  2.72s/it, current_loss=2.85, epoch=0, loss=2.82] 25%|██▌       | 10/40 [00:28<01:21,  2.72s/it, current_loss=2.84, epoch=0, loss=2.83] 28%|██▊       | 11/40 [00:29<01:16,  2.64s/it, current_loss=2.84, epoch=0, loss=2.83] 28%|██▊       | 11/40 [00:30<01:16,  2.64s/it, current_loss=2.82, epoch=0, loss=2.82] 30%|███       | 12/40 [00:31<01:12,  2.60s/it, current_loss=2.82, epoch=0, loss=2.82] 30%|███       | 12/40 [00:33<01:12,  2.60s/it, current_loss=2.79, epoch=0, loss=2.82] 32%|███▎      | 13/40 [00:34<01:10,  2.62s/it, current_loss=2.79, epoch=0, loss=2.82] 32%|███▎      | 13/40 [00:36<01:10,  2.62s/it, current_loss=2.83, epoch=0, loss=2.82] 35%|███▌      | 14/40 [00:37<01:10,  2.73s/it, current_loss=2.83, epoch=0, loss=2.82] 35%|███▌      | 14/40 [00:38<01:10,  2.73s/it, current_loss=2.85, epoch=0, loss=2.82] 38%|███▊      | 15/40 [00:40<01:09,  2.77s/it, current_loss=2.85, epoch=0, loss=2.82] 38%|███▊      | 15/40 [00:41<01:09,  2.77s/it, current_loss=2.84, epoch=0, loss=2.83] 40%|████      | 16/40 [00:43<01:07,  2.81s/it, current_loss=2.84, epoch=0, loss=2.83] 40%|████      | 16/40 [00:44<01:07,  2.81s/it, current_loss=2.83, epoch=0, loss=2.83] 42%|████▎     | 17/40 [00:45<01:04,  2.82s/it, current_loss=2.83, epoch=0, loss=2.83] 42%|████▎     | 17/40 [00:47<01:04,  2.82s/it, current_loss=2.84, epoch=0, loss=2.83] 45%|████▌     | 18/40 [00:48<01:02,  2.83s/it, current_loss=2.84, epoch=0, loss=2.83] 45%|████▌     | 18/40 [00:50<01:02,  2.83s/it, current_loss=2.89, epoch=0, loss=2.83] 48%|████▊     | 19/40 [00:51<01:00,  2.87s/it, current_loss=2.89, epoch=0, loss=2.83] 48%|████▊     | 19/40 [00:53<01:00,  2.87s/it, current_loss=2.83, epoch=0, loss=2.83] 50%|█████     | 20/40 [00:54<00:57,  2.89s/it, current_loss=2.83, epoch=0, loss=2.83] 50%|█████     | 20/40 [00:56<00:57,  2.89s/it, current_loss=2.8, epoch=0, loss=2.83]  52%|█████▎    | 21/40 [00:57<00:55,  2.90s/it, current_loss=2.8, epoch=0, loss=2.83] 52%|█████▎    | 21/40 [00:59<00:55,  2.90s/it, current_loss=2.83, epoch=0, loss=2.83] 55%|█████▌    | 22/40 [01:00<00:52,  2.94s/it, current_loss=2.83, epoch=0, loss=2.83] 55%|█████▌    | 22/40 [01:02<00:52,  2.94s/it, current_loss=2.85, epoch=0, loss=2.83] 57%|█████▊    | 23/40 [01:03<00:49,  2.92s/it, current_loss=2.85, epoch=0, loss=2.83] 57%|█████▊    | 23/40 [01:05<00:49,  2.92s/it, current_loss=2.82, epoch=0, loss=2.83] 60%|██████    | 24/40 [01:06<00:46,  2.91s/it, current_loss=2.82, epoch=0, loss=2.83] 60%|██████    | 24/40 [01:08<00:46,  2.91s/it, current_loss=2.83, epoch=0, loss=2.83] 62%|██████▎   | 25/40 [01:09<00:44,  2.95s/it, current_loss=2.83, epoch=0, loss=2.83] 62%|██████▎   | 25/40 [01:11<00:44,  2.95s/it, current_loss=2.89, epoch=0, loss=2.83] 65%|██████▌   | 26/40 [01:12<00:41,  2.93s/it, current_loss=2.89, epoch=0, loss=2.83] 65%|██████▌   | 26/40 [01:14<00:41,  2.93s/it, current_loss=2.83, epoch=0, loss=2.83] 68%|██████▊   | 27/40 [01:15<00:37,  2.91s/it, current_loss=2.83, epoch=0, loss=2.83] 68%|██████▊   | 27/40 [01:16<00:37,  2.91s/it, current_loss=2.82, epoch=0, loss=2.83] 70%|███████   | 28/40 [01:18<00:35,  2.95s/it, current_loss=2.82, epoch=0, loss=2.83] 70%|███████   | 28/40 [01:19<00:35,  2.95s/it, current_loss=2.78, epoch=0, loss=2.83] 72%|███████▎  | 29/40 [01:21<00:32,  2.96s/it, current_loss=2.78, epoch=0, loss=2.83] 72%|███████▎  | 29/40 [01:22<00:32,  2.96s/it, current_loss=2.86, epoch=0, loss=2.83] 75%|███████▌  | 30/40 [01:24<00:29,  2.97s/it, current_loss=2.86, epoch=0, loss=2.83] 75%|███████▌  | 30/40 [01:25<00:29,  2.97s/it, current_loss=2.81, epoch=0, loss=2.83] 78%|███████▊  | 31/40 [01:27<00:26,  2.97s/it, current_loss=2.81, epoch=0, loss=2.83] 78%|███████▊  | 31/40 [01:28<00:26,  2.97s/it, current_loss=2.81, epoch=0, loss=2.83] 80%|████████  | 32/40 [01:30<00:23,  2.92s/it, current_loss=2.81, epoch=0, loss=2.83] 80%|████████  | 32/40 [01:31<00:23,  2.92s/it, current_loss=2.83, epoch=0, loss=2.83] 82%|████████▎ | 33/40 [01:32<00:20,  2.89s/it, current_loss=2.83, epoch=0, loss=2.83] 82%|████████▎ | 33/40 [01:34<00:20,  2.89s/it, current_loss=2.8, epoch=0, loss=2.83]  85%|████████▌ | 34/40 [01:35<00:17,  2.89s/it, current_loss=2.8, epoch=0, loss=2.83] 85%|████████▌ | 34/40 [01:37<00:17,  2.89s/it, current_loss=2.86, epoch=0, loss=2.83] 88%|████████▊ | 35/40 [01:38<00:14,  2.86s/it, current_loss=2.86, epoch=0, loss=2.83] 88%|████████▊ | 35/40 [01:40<00:14,  2.86s/it, current_loss=2.78, epoch=0, loss=2.83] 90%|█████████ | 36/40 [01:41<00:11,  2.89s/it, current_loss=2.78, epoch=0, loss=2.83] 90%|█████████ | 36/40 [01:43<00:11,  2.89s/it, current_loss=2.81, epoch=0, loss=2.83] 92%|█████████▎| 37/40 [01:44<00:08,  2.95s/it, current_loss=2.81, epoch=0, loss=2.83] 92%|█████████▎| 37/40 [01:46<00:08,  2.95s/it, current_loss=2.85, epoch=0, loss=2.83] 95%|█████████▌| 38/40 [01:47<00:05,  2.94s/it, current_loss=2.85, epoch=0, loss=2.83] 95%|█████████▌| 38/40 [01:49<00:05,  2.94s/it, current_loss=2.84, epoch=0, loss=2.83] 98%|█████████▊| 39/40 [01:50<00:02,  2.97s/it, current_loss=2.84, epoch=0, loss=2.83] 98%|█████████▊| 39/40 [01:51<00:02,  2.87s/it, current_loss=2.84, epoch=0, loss=2.83]
Traceback (most recent call last):
  File "run_joint.py", line 55, in <module>
    graph2route_pd.main(params)
  File "/home/sentanoe/joint_training/algorithm/graph2route_pd/train.py", line 232, in main
    run(params, Graph2RouteDataset, process_batch, test_model,collate_fn)
  File "/home/sentanoe/joint_training/my_utils/utils.py", line 1205, in run
    result_dict = train_val_test_g2r(train_loader, val_loader, test_loader, modelRoute, device, PROCESS_BATCH, TEST_MODEL, params, save2FileRoute,save2FileArrivalTime,modelArrivalTime)
  File "/home/sentanoe/joint_training/my_utils/utils.py", line 932, in train_val_test_g2r
    pred, loss_g2r, b_V_val_unmasked, index= process_batch(batch, modelRoute, device, params['pad_value'])
  File "/home/sentanoe/joint_training/algorithm/graph2route_pd/train.py", line 71, in process_batch
    pred_scores, pred_pointers, b_V_val_unmasked = model.forward(V, V_reach_mask, V_ft, V_pt, V_dt, V_num, V_dispatch_mask, E, E_ed,  E_sd, np.array(E_mask), start_idx, cou)
  File "/home/sentanoe/joint_training/algorithm/graph2route_pd/model.py", line 254, in forward
    b_node_h = self.model_tft(cou[:,0].reshape(B, T, 1), b_node_h.reshape(B, T, -1))
  File "/home/sentanoe/miniconda3/envs/env_graph2route/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sentanoe/joint_training/algorithm/graph2route_pd/tft.py", line 377, in forward
    encoder_output, hidden = self.encode(embeddings_encoder)
  File "/home/sentanoe/joint_training/algorithm/graph2route_pd/tft.py", line 331, in encode
    output, (hidden, cell) = self.lstm_encoder(x, (hidden, hidden))
  File "/home/sentanoe/miniconda3/envs/env_graph2route/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sentanoe/miniconda3/envs/env_graph2route/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 689, in forward
    self.check_forward_args(input, hx, batch_sizes)
  File "/home/sentanoe/miniconda3/envs/env_graph2route/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 634, in check_forward_args
    'Expected hidden[0] size {}, got {}')
  File "/home/sentanoe/miniconda3/envs/env_graph2route/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 226, in check_hidden_size
    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))
RuntimeError: Expected hidden[0] size (1, 25, 160), got [1, 64, 160]
srun: error: stud-000: task 0: Exited with exit code 1
